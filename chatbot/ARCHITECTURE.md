# ðŸ—ï¸ Architecture Overview

> Simplified architecture guide for developers

---

## System Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FRONTEND (React/Next.js)               â”‚
â”‚  - AIAssistantChatEnhanced              â”‚
â”‚  - AIStreamingHandler                   â”‚
â”‚  - useAIToolCalls                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ HTTP/SSE
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API ROUTES (Next.js)                   â”‚
â”‚  - /api/v2/ai/chat                      â”‚
â”‚  - /api/v2/question-generator/*         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SERVICES                               â”‚
â”‚  - Context Builder (3-layer memory)     â”‚
â”‚  - Document Ingestion (parallel)        â”‚
â”‚  - Memory Management (pgvector)         â”‚
â”‚  - Vector Indexing (embeddings)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATABASE                               â”‚
â”‚  - PostgreSQL + pgvector                â”‚
â”‚  - Multi-tenant schemas                 â”‚
â”‚  - HNSW indexes                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Design Patterns

### 1. Server-Sent Events (SSE)

**Why:** Real-time streaming without WebSocket complexity

```typescript
// Backend sends
res.write(`data: ${JSON.stringify({ type: 'content', content: 'chunk' })}\n\n`);

// Frontend receives
const reader = response.body.getReader();
// Parse and display in real-time
```

### 2. Tool Calling

**Flow:** LLM decides â†’ Backend streams â†’ Frontend executes â†’ Continue

```typescript
// LLM calls tool
{ type: 'tool_call', name: 'previewQuestions', args: {...} }

// Frontend executes
const questions = convertQuestions(args);
showInUI(questions);

// Send results back for continuation
await fetch('/api/v2/ai/chat', {
  body: JSON.stringify({ toolResults: [...] })
});
```

### 3. Three-Layer Memory

**Immediate Context** (in-memory)
- Current conversation
- Active documents

**Long-term Context** (pgvector)
- Semantic search past conversations
- Related documents

**Synthesized Summary** (LLM-generated)
- AI creates context summary
- Cached in Redis

### 4. Background Processing

**Critical:** Preserve tenant context!

```typescript
// âœ… Capture headers BEFORE async
const headers = { 'x-tenant-tag': req.headers['x-tenant-tag'] };

setImmediate(async () => {
  const bgReq = { headers };
  await process({ req: bgReq });
});
```

---

## Performance Optimizations

### Async Upload (98% faster)
```
Before: Upload â†’ Extract â†’ Chunk â†’ Index â†’ Return (90s)
After:  Upload â†’ Extract â†’ Return (2s) + Background processing
```

### Parallel PDF (75% faster)
```
Before: Page 1 (40s) â†’ Page 2 (40s) â†’ ... (sequential)
After:  Batch [1-6] (40s) â†’ Batch [7-12] (40s) (parallel)
```

### Smart Context (70% smaller)
```
Before: Load full document (50KB)
After:  Load relevant chunks (15KB)
```

---

## Multi-tenant Architecture

**Tenant Identification:**
1. JWT in x-tenant-tag header
2. LRU cache (1ms lookup)
3. Redis fallback (10ms)
4. DB lookup (50ms)

**Schema Isolation:**
```sql
-- Each tenant gets dedicated schema
CREATE SCHEMA "tenant_abc123";

-- Prisma connects to correct schema
?schema=tenant_abc123
```

---

## Data Flow Examples

### Chat Message Flow
```
User message
  â†’ Frontend (AIAssistantChatEnhanced)
  â†’ SSE connection (AIStreamingHandler)
  â†’ Backend (/api/v2/ai/chat)
  â†’ Context Builder (3 layers)
  â†’ LLM (DeepSeek/OpenAI)
  â†’ Stream response (SSE)
  â†’ Frontend displays (real-time)
```

### Document Upload Flow
```
File upload
  â†’ Validation
  â†’ Text extraction (2s)
  â†’ Return to user âœ…
  
Background (non-blocking):
  â†’ Chunking (12s)
  â†’ Embedding generation (35s)
  â†’ Vector indexing (HNSW)
  â†’ Memory storage (3s)
```

### Tool Call Flow
```
User: "Create 5 questions"
  â†’ LLM detects intent
  â†’ Calls previewQuestions tool
  â†’ Streams partial questions (isPartial: true)
  â†’ Frontend shows live preview
  â†’ Complete questions (isPartial: false)
  â†’ Send tool results back
  â†’ LLM continues with summary
```

---

## Key Services

### ContextBuilderService
```typescript
buildContext({
  query,
  previousMessages,
  attachments,
  enableMemory: true
}) â†’ {
  immediateContext,    // Recent msgs, docs
  longTermContext,     // Semantic memories
  synthesizedSummary   // AI summary
}
```

### DocumentIngestionService
```typescript
ingestDocument(file, userId, options) â†’ {
  documentId,
  extractedText,
  fingerprintExists
}
```

### MemoryManagementService
```typescript
retrieveRelevantMemories(query, options) â†’ Memory[]
// Uses pgvector cosine similarity
```

### VectorIndexingService
```typescript
indexDocument(documentId, options) â†’ {
  success,
  indexedChunks
}
```

---

## Database Schema (Simplified)

```sql
-- Documents
DocumentIndex {
  id, filename, extracted_text, fingerprint
}

-- Chunks for vector search
DocumentChunk {
  id, document_id, content, embedding vector(1536)
}

-- Conversation memory
ConversationMemory {
  id, summary, embedding vector(1536), metadata
}

-- Indexes
CREATE INDEX embedding_hnsw_idx 
USING hnsw (embedding vector_cosine_ops);
```

---

## Security

- JWT authentication
- Tenant isolation (schemas)
- API key validation
- CORS policies
- Rate limiting (planned)

---

## Monitoring

**Key Metrics:**
- Upload time (target: <5s)
- Chat response time (target: <8s)
- Memory retrieval time (target: <1s)
- Error rate (target: <0.1%)

**Logs:**
```
[Background] Processing for <id>
[Memory] Retrieved X memories (similarity > 0.7)
[PDF] âš¡ Processing X pages with Y concurrent workers
```

---

## Further Reading

- **Complete docs:** [README.md](./README.md)
- **Setup guide:** [QUICK_START.md](./QUICK_START.md)
- **API reference:** In README.md
- **Executive summary:** [SUMMARY.md](./SUMMARY.md)

---

**For detailed architecture, see full README.md documentation.**
